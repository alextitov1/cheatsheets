
# Podman/Docker OCI

## Get Help

podman --help

man podman-run # sudo mandb

## Basic commands

```sh
podman ps
podman logs <ContainerId>

podman images
podman image inspect <ImageId>
podman image tree hello-server:bad

podman exec -it <ContainerId> sh

podman stop $(podman ps -aq)
podman rm $(podman ps -aq)

podman inspect --format='{{.State.Running}}' httpd

## stop/terminate
# Podman sends a SIGTERM signal to stop the container gracefully, but the application ignores the signal. After 5 seconds, Podman sends a SIGKILL signal to the container. The --time flag indicates the time that Podman waits before sending a SIGKILL signal to forcefully stop the container.
podman stop greeter --time=5

## build 
podman build -t localhost/not-squashed .

# squash CoW layers
podman build --squash -t localhost/squashed .
podman build --squash-all -t localhost/squashed .
podman images --format="{{.Names}}\t{{.Size}}"

podman pod ?????
```

## Network

```sh
podman network --help
```

### Basic command

```sh
podman network create example-net
podman run -d --name my-container --net example-net container-image:latest

podman network ls
podman network inspect <NetworkId>
podman port <ContainerId>

# When you create new containers, you can connect them to multiple networks by specifying network names in a comma-separated list
podman run -d --name double-connector --net postgres-net,redis-net container-image:latest


# Alternatively, if the my-container container is already running, then run the following command to connect it to the example-net network

podman network connect example-net my-container
```

### DNS

DNS is disabled in the default podman network. To enable DNS resolution between containers, create a Podman network and connect your containers to that network.


### Port-Forwarding

```sh
podman run -p 8075:80 my-app
podman run -p 127.0.0.1:8075:80 my-app
podman port my-app
podman port --all

podman inspect my-app -f '{{.NetworkSettings.Networks.apps.IPAddress}}'
```

## Storage

### basic commands
```sh
podman inspect VOLUME_ID
podman volume prune
podman volume create VOLUME_NAME

podman volume ls --format="{{.Name}}\t{{.Mountpoint}}"
```

#### diff

display the changes made to a container's filesystem since it was started

```sh
podman diff elastic_maxwell
```

#### cp

copy files/folders between a container and the local filesystem

```sh
podman cp index.html elastic_maxwell:/var/wwww/index.html
```

### Volumes and Bind mounts

Volumes - managed by Podman

```sh
podman volume create http-data
podman volume inspect http-data
```

for rootless containers, Podman stores volume in the `$HOME/.local/share/containers/storage/volumes` directory.

Bind mounts - can exist anywhere on the host filesystem

Both volumes and bind mounts can use `--volume` or `-v` parameter

```sh
# --volume /path/on/host:/path/in/container:OPTIONS

# Bind mounts with the read-only option
podman run --volume  /www:/var/www/html:ro ubi8/httpd-24:latest

# Volume mount into a container
podman run --volume http-data:/var/www/html ubi8/httpd-24:latest
## Because Podman manages the volume, you do not need to configure SELinux permissions.

### import/export volumes
podman volume export http_data --output web_data.tar.gz
podman volume import web_data.tar.gz
```

Alternatively, you can use the `--mount` parameter

```sh
--mount type=TYPE,source=/path/on/host,destination=/path/in/container
# type= bind | volume | tmpfs
```

#### Storing Data with a tmpfs Mount

Some application  cannot ue the default COW file system in a specific directory for performance reasons, but do not use persistence or data sharing. In this case, you can use the `tmpfs` mount type, which means that the data in mount is ephemeral but does not use the COW file system.

```sh
podman run -e POSTGRESQL_ADMIN_PASSWORD=redhat --network lab-net \
  --mount  type=tmpfs,tmpfs-size=512M,destination=/var/lib/pgsql/data \
  registry.redhat.io/rhel9/postgresql-13:1
```

#### Troubleshoot Bind mounts

podman-unshare - Run a command inside of a modified user namespace

```sh
podman unshare ls -l /www/
```

SELinux
```
ls -Zd /www
system_u:object_r:default_t:s0:c228,c359 /www
```
The output shows the SELinux context label system_u:object_r:default_t:s0:c228,c359, which has the default_t type. A container must have the container_file_t SELinux type to have access to the bind mount. SELinux is out of scope for this course.

To fix the SELinux configuration, add the :z or :Z option to the bind mount:

* Lower case z lets different containers share access to a bind mount.

* Upper case Z provides the container with exclusive access to the bind mount

```sh
podman run -p 8080:8080 --volume /www:/var/www/html:Z ubi8/httpd-24:latest
```

After adding the corresponding option, run the ls -Zd command and notice the right SELinux type.

```
[user@host ~]$ ls -Zd /www
system_u:object_r:container_file_t:s0:c240,c717 /www
```

## Container Registry

### RedHat registries

```sh
registry.access.redhat.com # requires no authentication
registry.redhat.io # requires authentication
registry.connect.redhat.com # requires authentication third-party products
```

#### useful images

```sh
registry.access.redhat.com/ubi9 # RedHat Universal Base Image
registry.access.redhat.com/ubi9/python-39 # Python 3.9 on UBI9
```

### podman registry config

podman registries config file
`/etc/containers/registries.conf`

```sh
grep ^[^#] /etc/containers/registries.conf
``` 

### podman registry operation

#### search

```sh
podman search nginx
```

#### login

```sh
podman login registry.redhat.io
```

Podman stores the credentials in the ${XDG_RUNTIME_DIR}/containers/auth.json file
```
[user@host ~]$ cat ${XDG_RUNTIME_DIR}/containers/auth.json
{
	"auths": {
		"registry.redhat.io": {
			"auth": "dXNlcjpodW50ZXIy"
		}
	}
}
[user@host ~]$ echo -n dXNlcjpodW50ZXIy | base64 -d
user:hunter2
```

### quay

Quay.io - redhat public registry

container registry - local instance
```
 registry.redhat.io/quay/quay-rhel8
```


Nexus - the artifact repository


### utility

`scopeo` is a command line utility that allows you to inspect and manage container images.

```sh
skopeo copy --dest-tls-verify=false \
  docker://${RHOCP_REGISTRY}/default/python:3.9-ubi8 \
  docker://registry.ocp4.example.com:8443/developer/python:3.9-ubi8
```



# Dockerfile/Containerfile

## BaseImage
UBI - universal base images

* **Standard**: This is the primary UBI, which includes DNF, systemd, and utilities such as gzip and tar.

* **Init**: Simplifies running multiple applications within a single container by managing them with systemd.

* **Minimal**: This image is smaller than the init image and still provides nice-to-have features. This image uses the microdnf minimal package manager instead of the full-sized version of DNF.

* **Micro**: This is the smallest available UBI because it only includes the bare minimum number of packages. For example, this image does not include a package manager.

## Containerfile Instructions

Containerfiles use a small domain-specific language (DSL)

* FROM 

* WORKDIR

* COPY and ADD
> The ADD instruction adds the following functionality: 
> * Copying files from URLs.
> * Unpacking tar archives in the destination image.

> Because the ADD instruction adds functionality that might not be obvious, developers tend to prefer the COPY instruction for copying local files into the container image.

* RUN (Runs a command in the container)

Runs a command when the container is started. This command is passed to the executable defined by ENTRYPOINT. Base images define a default ENTRYPOINT, which is usually a shell executable, such as Bash.

> Neither ENTRYPOINT nor CMD run when building a container image. Podman executes them when you start a container from the image.

* USER (Instructions that follow the USER instruction run as this user, including the CMD instruction.)

* LABEL (Adds a key-value pair to the metadata of the image for organization and image selection)

* EXPOSE (This instruction does not bind the port on the host and is for documentation purposes)

* ENV (You can declare multiple ENV instructions within the Containerfile)

* ARG (Defines build-time variables, typically to make a customizable container build)

<details>
<summary>ARG usage example</summary>

```Docker

ARG VERSION="1.16.8" BIN_DIR=/usr/local/bin/

ENV VERSION=${VERSION} \
    BIN_DIR=${BIN_DIR}

RUN curl "https://dl.example.io/${VERSION}/example-linux-amd64" \
        -o ${BIN_DIR}/example

```
</details>

* VOLUME (Defines where to store data outside of the container)

* ENTRYPOINT (Sets the executable to run when the container is started) 
> ENTRYPOINT ["executable", "param1", ... "paramN"]

* CMD
> CMD ["echo", "Hello", "Red Hat"]

## Multistage Builds

<details>
<summary> two stage build example </summary>

```Docker
# First stage
FROM registry.access.redhat.com/ubi8/nodejs-14:1 as builder
COPY ./ /opt/app-root/src/
RUN npm install
RUN npm run build

# Second stage
FROM registry.access.redhat.com/ubi8/nginx-120
COPY --from=builder /opt/app-root/src/ /usr/share/nginx/html
```

</details>


# Rootless Podman

## User Mapping
Podman maps users inside of the container to unprivileged users on the host system by using *subordinate ID* ranges
```sh
/etc/subuid
/etc/subgid
```

To generate the subordinate ID ranges, use the usermod command:
```sh
sudo usermod --add-subuids 100000-165535 \
  --add-subgids 100000-165535 student
# The /etc/subuid and /etc/subgid files must exist before you define the subordinate ID ranges

# for the new subordinate ID ranges to take effect:
podman system migrate
```

To verify the mapped user
```sh
podman run -it registry.access.redhat.com/ubi9/ubi id

podman top e6116477c5c9 huser user
```
> When you execute a container with elevated privileges on the host machine, the root mapping does not take place even when you define subordinate ID ranges



# Compose

`podman-compose up`

* -d, --detach: Start containers in the background.
* --force-recreate: Re-create containers on start.
* -V, --renew-anon-volumes: Re-create anonymous volumes.
* --remove-orphans: Remove containers that do not correspond to services that are defined in the current Compose file.

`podman-compose stop/down`

`podman-compose logs -n -f`

## Podman Pods

`podman generate kube` - generate a Kubernetes YAML file from a Podman pod definition

`podman play kube` - create a pod from a Kubernetes YAML file


### The Compose File

* `version` (deprecated): Specifies the Compose version used.
* `services`: Defines the containers used.
* `networks`: Defines the networks used by the containers.
* `volumes`: Specifies the volumes used by the containers.
* `configs`: Specifies the configurations used by the containers.
* `secrets`: Defines the secrets used by the containers.

#### Examples

<details>
<summary>example1</summary>

```yaml

```yaml
services:
  frontend:
    image: quay.io/example/frontend
    networks:
      - app-net
    ports:
      - "8082:8080"
  backend:
    image: quay.io/example/backend
    networks:
      - app-net
      - db-net
    depends_on:
     - db
  db:
    image: registry.redhat.io/rhel8/postgresql-13
    environment:
      POSTGRESQL_ADMIN_PASSWORD: redhat
    networks:
      - db-net
    volumes:
      - db-vol:/var/lib/postgresql/data

networks:
  app-net: {}
  db-net: {}

volume:
  db-vol: {}

```
</details>

### Installing Podman Compose

```sh
pip3 install podman-compose
```

# Troubleshooting

## Container Startup

```sh
podman ps -a
podman logs CONTAINER_ID
# podman logs -f CONTAINER_ID
```
## Container Networking

```sh
podman port CONTAINER_ID
```

To verify the application ports in use in the containe
```sh
podman exec -it CONTAINER ss -pant
```

Containers usually lack many commands. Run the host system commands within the container network namespace by using the `nsenter` command
```sh
# get the PID of the container
podman inspect CONTAINER_ID --format '{{.State.Pid}}'

sudo nsenter -n -t CONTAINER_PID ss -pant
```

To verify that every container is using a specific network
```sh
podman inspect CONTAINER_ID --format '{{.NetworkSettings.Networks}}'
## When containers communicate by using Podman networks, there is no port mapping involved.
```

# OpenShift

>A **project** is a RHOCP `resource` which is similar to the **namespace** Kubernetes resource

> `kubectl` utility can manage a RHOCP cluster

## Get help

```sh
oc explain deployment.spec.template.spec.containers.env
```

## OpenShift CLI

```sh
oc login https://api.ocp4.example.com:6443
oc get pod
oc create -f pod.yaml
oc delete
oc logs react-uipodman pod
oc explain pod.metadata.name
```
## Label Kubernetes Objects

Labels are key-value pairs that you define in the object.

```yaml
kind: Pod
apiVersion: v1
metadata:
  name: example-pod
  labels:
    app: example-pod
    group: developerspodman pod
```
```sh
oc get pod --selector group=developers
```
## Pods

A **pod** represents a group of one or multiple containers that share resources, such as a network interface or file system

### Create Pods declaratively 

```yaml
kind: Pod
apiVersion: v1
metadata:
  name: example-pod
  namespace: example-project
spec:
  containers:
  - name: example-container
    image: quay.io/example/awesome-container
    ports:
    - containerPort: 8080
    env:
    - name: GREETING
      value: "Hello from the awesome container"
```

### Create Pods imperatively

```sh
oc run example-pod \ # 1
  --image=quay.io/example/awesome-container \ # 2
  --env GREETING='Hello from the awesome container' \ # 3
  --port=8080 # 4
  # -o yaml # 5
# 1 The pod .metadata.name definition.
# 2 The image used for the single container in this pod.
# 3 The environment variable for the single container in this pod.
# 4 The port metadata definition.
# 5 The -o yaml option prints the YAML definition of the pod to the terminal.
```
## Services

To configure pod-to-pod communication use a Service object.

The default service type is **ClusterIP**, which means the service is used for pod-to-pod routing within the cluster.Other service types e.g. **LoadBalancer** service.

### Create a Service declaratively

```yaml
apiVersion: v1
kind: Service
metadata:
  name: backend
spec:
  ports:
  - port: 8080 # 1
    protocol: TCP
    targetPort: 8080 # 2
  selector: # 3
    app: backend-app

# 1 Service port. This is the port on which the service listens.
# 2 Target port. This is the pod port to which the service routes requests. This port corresponds to the containerPort value in the pod definition.
# 3 The selector configures which pods to target. In this case, the service routes to any pods that contain the app=backend-app label.
```
### Create a Service imperatively

```sh
oc expose pod backend-app \
  --port=8080 \
  --targetPort=8080 \
  --name=backend-app
```

### 76767

bare pod

Deployment

ReplicaSet

StatefulSet

## Multi-pod Applications example

```sh
oc create deployment gitea-postgres --port 5432 -o yaml \
  --image=registry.ocp4.example.com:8443/rhel9/postgresql-13:1 \
  --dry-run=client > postgres.yaml

oc create -f postgres.yaml

# Expose the PostgreSQL database on the gitea-postgres hostname
oc expose deployment gitea-postgres
oc get svc

# Expose the application within the RHOCP cluster
oc expose deployment gitea
oc expose service gitea

oc get route
```

# Utility

```sh
getent hosts <hostname>

```
`nsenter` is a command line utility that allows you to enter a namespace.

#  Links

[Understanding root inside and outside a container](https://www.redhat.com/en/blog/understanding-root-inside-and-outside-container)

[Application Container Security Guide](https://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-190.pdf)

[Podman Setup](https://github.com/containers/podman/blob/v4.2.0/docs/tutorials/rootless_tutorial.md)

[Podman Troubleshooting](https://github.com/containers/podman/blob/v4.2.0/troubleshooting.md)

[Shortcomings of Rootless Podman](https://github.com/containers/podman/blob/v4.2.0/rootless.md)

[Container Security Workshop](http://redhatgov.io/workshops/security_containers/)

## Storage

[Overlay.go](https://github.com/containers/podman/blob/v4.2.0/vendor/github.com/containers/storage/drivers/overlay/overlay.go)

[SELinux and Container File Permissions](https://www.redhat.com/sysadmin/user-namespaces-selinux-rootless-containers)

[Podman is gaining rootless overlay support](https://www.redhat.com/sysadmin/podman-rootless-overlay)

## Compose

[Podman Compose Vs Docker Compose](https://www.redhat.com/sysadmin/podman-compose-docker-compose)

## Networking

[nsenter](https://www.redhat.com/sysadmin/container-namespaces-nsenter)